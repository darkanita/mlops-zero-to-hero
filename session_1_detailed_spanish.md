# Sesi√≥n 1: Fundamentos MLOps y Configuraci√≥n del Entorno - Plan de Ense√±anza Detallado

**üåç Idiomas:** [English](session-1-detailed.md) | [Espa√±ol](session-1-detailed-ES.md)

**Duraci√≥n:** 4 horas  
**Formato:** Teor√≠a (1.5h) + Laboratorio Pr√°ctico (2.5h)  
**Tama√±o de Clase:** 8-20 estudiantes  
**Prerrequisitos:** Python b√°sico, conceptos ML, fundamentos Git

---

## üéØ Objetivos de Aprendizaje de la Sesi√≥n

Al finalizar esta sesi√≥n, los estudiantes ser√°n capaces de:
- Explicar qu√© es MLOps y por qu√© es cr√≠tico para proyectos ML modernos
- Identificar los desaf√≠os clave en la gesti√≥n del ciclo de vida ML
- Configurar un entorno de desarrollo MLOps profesional usando herramientas modernas
- Crear su primer experimento MLFlow con seguimiento apropiado
- Aplicar mejores pr√°cticas para organizaci√≥n de proyectos ML

---

## üìö Preparaci√≥n Pre-Sesi√≥n

### Configuraci√≥n del Instructor
- [ ] Entorno demo MLFlow ejecut√°ndose
- [ ] Datasets de muestra descargados
- [ ] Repositorio de c√≥digo preparado
- [ ] Conexi√≥n de internet de respaldo (para instalaci√≥n uv)
- [ ] Slides de presentaci√≥n listos

### Prerrequisitos del Estudiante
- [ ] Laptop con privilegios de administrador
- [ ] Git instalado y configurado
- [ ] Cuenta GitHub creada
- [ ] Familiaridad b√°sica con terminal/l√≠nea de comandos
- [ ] Python 3.8+ instalado (cualquier versi√≥n por ahora)

---

## üïê Parte 1: Introducci√≥n a MLOps (30 minutos)

### Gancho de Apertura (5 minutos)
**Comenzar con un escenario real:**
*"Imaginen que son cient√≠ficos de datos en Spotify. Han construido un modelo de recomendaci√≥n incre√≠ble que funciona perfectamente en su laptop con 95% de precisi√≥n. Pero cuando intentan desplegarlo a producci√≥n para servir a 400 millones de usuarios, todo se rompe. Las predicciones del modelo son diferentes, el c√≥digo falla, y nadie puede reproducir sus resultados. Por esto necesitamos MLOps."*

### Contenido Central (20 minutos)

#### ¬øQu√© es MLOps? (8 minutos)
**Definici√≥n:**
> MLOps es la pr√°ctica de combinar el desarrollo de Machine Learning (ML) con principios DevOps para automatizar y mejorar la entrega continua de modelos ML a producci√≥n.

**Componentes Clave:**
1. **Desarrollo de Modelos** - Seguimiento de experimentos, control de versiones
2. **Despliegue de Modelos** - Pipelines automatizados, containerizaci√≥n
3. **Monitoreo de Modelos** - Seguimiento de rendimiento, detecci√≥n de deriva
4. **Gobernanza de Modelos** - Cumplimiento, seguridad, aprobaciones

**Analog√≠a Visual:**
- Software Tradicional: C√≥digo ‚Üí Construir ‚Üí Probar ‚Üí Desplegar ‚Üí Monitorear
- MLOps: Datos + C√≥digo + Modelo ‚Üí Experimentar ‚Üí Validar ‚Üí Desplegar ‚Üí Monitorear ‚Üí Reentrenar

#### Por qu√© MLOps es Importante (7 minutos)
**Estad√≠sticas de la Crisis ML:**
- 87% de proyectos ML nunca llegan a producci√≥n
- Tiempo promedio de despliegue: 6-12 meses
- 90% de modelos se degradan en 6 meses sin monitoreo

**Problemas Reales que MLOps Resuelve:**
1. **"Funciona en mi m√°quina"** ‚Üí Entornos reproducibles
2. **"¬øD√≥nde est√° la versi√≥n 2.3 del modelo?"** ‚Üí Versionado de modelos
3. **"¬øEl modelo sigue siendo preciso?"** ‚Üí Monitoreo automatizado
4. **"¬øQui√©n aprob√≥ este modelo?"** ‚Üí Flujos de gobernanza

**Impacto Empresarial:**
- Netflix: MLOps reduce el tiempo de despliegue de modelos de meses a d√≠as
- Uber: Reentrenamiento automatizado previene ca√≠da del 40% en precisi√≥n del modelo
- Airbnb: Plataforma MLOps sirve 150+ modelos a 1M+ predicciones/segundo

#### MLOps vs DevOps Tradicional (5 minutos)
| Aspecto | DevOps Tradicional | MLOps |
|---------|-------------------|-------|
| **Artefactos** | C√≥digo | C√≥digo + Datos + Modelos |
| **Testing** | Tests unitarios | Tests de datos + Tests de modelos |
| **Despliegue** | Blue/green | Pruebas A/B + Canary |
| **Monitoreo** | M√©tricas del sistema | Rendimiento del modelo + deriva |
| **Rollback** | Versi√≥n anterior del c√≥digo | Modelo anterior + reentrenamiento |

### Discusi√≥n Interactiva (5 minutos)
**Preguntas para estudiantes:**
1. "¬øEn qu√© proyectos ML han trabajado? ¬øQu√© desaf√≠os enfrentaron para llevarlos a producci√≥n?"
2. "En sus proyectos actuales/pasados, ¬øc√≥mo rastrean experimentos?"
3. "¬øC√≥mo saben si su modelo desplegado sigue funcionando correctamente?"

---

## üïê Parte 2: Visi√≥n General del Ecosistema MLFlow (45 minutos)

### Introducci√≥n a MLFlow (10 minutos)
**¬øQu√© es MLFlow?**
MLFlow es una plataforma open-source para gestionar el ciclo de vida completo de machine learning, incluyendo experimentaci√≥n, reproducibilidad, despliegue y un registro central de modelos.

**¬øPor qu√© MLFlow?**
- **Open Source** - Sin vendor lock-in, comunidad activa
- **Agn√≥stico al Lenguaje** - Soporte para Python, R, Java, Scala
- **Agn√≥stico al Framework** - Funciona con scikit-learn, TensorFlow, PyTorch, etc.
- **Agn√≥stico a la Nube** - Ejecuta en AWS, Azure, GCP, o on-premises

### Profundizaci√≥n en Componentes MLFlow (25 minutos)

#### 1. MLFlow Tracking (8 minutos)
**Prop√≥sito:** Registrar y consultar experimentos (c√≥digo, datos, configuraci√≥n, resultados)

**Conceptos Clave:**
- **Experimento:** Grupo nombrado de ejecuciones (ej. "customer-churn-model")
- **Run:** Ejecuci√≥n √∫nica de c√≥digo ML
- **Par√°metros:** Valores de entrada (hiperpar√°metros, configuraci√≥n)
- **M√©tricas:** Valores num√©ricos a optimizar (precisi√≥n, RMSE)
- **Artefactos:** Archivos de salida (modelos, gr√°ficos, datos)

**Demo en Vivo:** Mostrar UI de MLFlow con experimento de ejemplo

#### 2. MLFlow Projects (7 minutos)
**Prop√≥sito:** Empaquetar c√≥digo ML para ejecuciones reproducibles

**Caracter√≠sticas Clave:**
- **Archivo MLproject:** Define puntos de entrada y dependencias
- **Gesti√≥n de entornos:** Conda, Docker, virtualenv
- **Ejecuci√≥n remota:** Ejecutar en diferentes entornos
- **Paso de par√°metros:** Interfaz de l√≠nea de comandos

**Ejemplo de archivo MLproject:**
```yaml
name: My ML Project
conda_env: conda.yaml
entry_points:
  main:
    parameters:
      alpha: {type: float, default: 0.5}
    command: "python train.py --alpha {alpha}"
```

#### 3. MLFlow Models (5 minutos)
**Prop√≥sito:** Formato est√°ndar para empaquetar modelos ML

**Beneficios Clave:**
- **M√∫ltiples sabores:** scikit-learn, tensorflow, pytorch, etc.
- **Interfaz unificada:** Misma API de predicci√≥n sin importar el framework
- **Listo para despliegue:** Puede desplegarse en varias plataformas
- **Metadatos:** Firma del modelo, requisitos, esquema entrada/salida

#### 4. MLFlow Model Registry (5 minutos)
**Prop√≥sito:** Almac√©n central para gestionar el ciclo de vida del modelo

**Caracter√≠sticas Clave:**
- **Versionado de modelos:** Rastrear evoluci√≥n del modelo
- **Transiciones de etapa:** Development ‚Üí Staging ‚Üí Production
- **Flujos de aprobaci√≥n:** Controlar promoci√≥n de modelos
- **Seguimiento de linaje:** Conectar modelos con experimentos

### Arquitectura y Despliegue MLFlow (10 minutos)

#### Patrones de Despliegue
1. **Desarrollo Local:**
   ```bash
   mlflow ui  # Ejecuta en localhost:5000
   ```

2. **Configuraci√≥n de Equipo:**
   ```bash
   mlflow server --backend-store-uri sqlite:///mlflow.db \
                 --default-artifact-root ./artifacts \
                 --host 0.0.0.0 --port 5000
   ```

3. **Configuraci√≥n de Producci√≥n:**
   ```bash
   mlflow server --backend-store-uri postgresql://user:pass@host/db \
                 --default-artifact-root s3://bucket/path \
                 --host 0.0.0.0 --port 5000
   ```

#### Ecosistema de Integraci√≥n
- **Plataformas Cloud:** AWS SageMaker, Azure ML, GCP Vertex AI
- **Orquestaci√≥n:** Apache Airflow, Kubeflow, Prefect
- **Monitoreo:** Prometheus, Grafana, DataDog
- **Almacenamiento:** S3, Azure Blob, GCS, HDFS

---

## üïê Parte 3: Mejores Pr√°cticas del Entorno de Desarrollo (15 minutos)

### Gesti√≥n Moderna de Entornos Python (8 minutos)
**Por qu√© la Gesti√≥n de Entornos es Importante:**
- Conflictos de dependencias entre proyectos
- Reproducibilidad entre miembros del equipo
- Seguridad (evitar instalaci√≥n global de paquetes)
- Consistencia de versiones

**Evoluci√≥n de Herramientas Python:**
- **Forma antigua:** `pip install` globalmente (üíÄ infierno de dependencias)
- **Mejor:** `virtualenv` + `pip` (gesti√≥n manual)
- **Bueno:** `conda` (pesado pero integral)
- **Moderno:** `uv` (r√°pido, simple, moderno)

**¬øPor qu√© uv?**
- **10-100x m√°s r√°pido** que pip
- **Basado en Rust** para velocidad y confiabilidad
- **Sintaxis simple** f√°cil de aprender
- **Est√°ndares modernos** (sigue est√°ndares PEP)
- **Amigable con Docker** para despliegue

### Control de Versiones para Proyectos ML (4 minutos)
**Desaf√≠os Espec√≠ficos de ML en Git:**
- Datasets grandes no pueden ir en Git
- Notebooks Jupyter crean diffs desordenados
- Archivos de modelos son binarios y grandes
- Resultados de experimentos necesitan seguimiento

**Mejores Pr√°cticas:**
- `.gitignore` para directorios data/ y models/
- Hacer commit de notebooks con outputs limpiados
- Usar MLFlow para resultados de experimentos, no Git
- Separar versionado de datos/modelos del c√≥digo

### Principios de Reproducibilidad (3 minutos)
**La Pir√°mide de Reproducibilidad:**
1. **Entorno** - Mismos paquetes, mismas versiones
2. **Datos** - Mismos datasets, mismo preprocesamiento
3. **C√≥digo** - Mismos algoritmos, mismos par√°metros
4. **Infraestructura** - Mismo hardware, mismo OS

**Herramientas para Cada Nivel:**
- Entorno: `uv`, Docker
- Datos: Artefactos MLFlow, checksums
- C√≥digo: Git, proyectos MLFlow
- Infraestructura: Docker, plantillas cloud

---

## üõ†Ô∏è Parte 4: Laboratorio Pr√°ctico (2.5 horas)

### Lab 1: Configuraci√≥n del Entorno con uv (45 minutos)

#### Paso 1: Instalar uv (10 minutos)
**Para que los estudiantes sigan:**

```bash
# Instalar uv (gestor r√°pido de paquetes Python)
# macOS/Linux:
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows:
powershell -c "irm https://astral.sh/uv/install.sh | iex"

# Verificar instalaci√≥n
uv --version
```

**Soluci√≥n de Problemas:**
- Si curl falla: Descargar desde https://github.com/astral-sh/uv/releases
- Si Windows security bloquea: Usar `--execution-policy bypass`
- Si detr√°s de firewall corporativo: Usar m√©todo de instalaci√≥n alternativo

#### Paso 2: Crear Estructura del Proyecto (15 minutos)
```bash
# Crear proyecto del curso MLOps
uv init mlops-course
cd mlops-course

# Examinar la estructura generada
ls -la
cat pyproject.toml
```

**Explicar pyproject.toml:**
```toml
[project]
name = "mlops-course"
version = "0.1.0"
description = "Curso MLOps usando MLFlow"
authors = [
    {name = "Tu Nombre", email = "tu.email@ejemplo.com"}
]
dependencies = []

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

#### Paso 3: Agregar Dependencias (10 minutos)
```bash
# Agregar dependencias ML centrales
uv add mlflow[extras] scikit-learn pandas numpy matplotlib seaborn

# Agregar dependencias API
uv add fastapi uvicorn python-dotenv

# Agregar herramientas de desarrollo (grupo separado)
uv add pytest black ruff mypy pre-commit --group dev

# Agregar librer√≠as ML opcionales
uv add optuna sentence-transformers --group ml

# Activar entorno
uv sync
source .venv/bin/activate  # Linux/Mac
# o .venv\Scripts\activate  # Windows
```

**Verificar instalaci√≥n:**
```bash
python -c "import mlflow; print(mlflow.__version__)"
mlflow --version
```

#### Paso 4: Configuraci√≥n de Estructura del Proyecto (10 minutos)
```bash
# Crear estructura de proyecto profesional
mkdir -p src/{data,models,evaluation,utils}
mkdir -p tests/{unit,integration}
mkdir -p notebooks
mkdir -p docker
mkdir -p .github/workflows

# Crear archivos __init__.py
touch src/__init__.py
touch src/data/__init__.py
touch src/models/__init__.py
touch src/evaluation/__init__.py
touch src/utils/__init__.py
```

**Crear .gitignore:**
```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Entornos virtuales
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# MLFlow
mlruns/
mlartifacts/

# Datos
data/raw/
data/processed/
*.csv
*.xlsx
*.json
*.pkl

# Modelos
models/
*.joblib
*.pickle

# Jupyter Notebook
.ipynb_checkpoints
*.ipynb

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db
```

### Lab 2: Configuraci√≥n del Proyecto e Integraci√≥n Git (30 minutos)

#### Paso 1: Configuraci√≥n del Repositorio Git (10 minutos)
```bash
# Inicializar repositorio Git
git init
git add .gitignore
git commit -m "Initial commit: project structure"

# Conectar a GitHub (los estudiantes deben crear repo primero)
git remote add origin https://github.com/USERNAME/mlops-course.git
git branch -M main
git push -u origin main
```

#### Paso 2: Configuraci√≥n del Entorno (10 minutos)
**Crear archivo .env:**
```bash
# Crear configuraci√≥n de entorno
cat > .env << EOF
# Configuraci√≥n MLFlow
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=iris-classification

# Configuraci√≥n Base de Datos (para uso posterior)
DATABASE_URL=sqlite:///mlflow.db

# Configuraci√≥n API
API_HOST=0.0.0.0
API_PORT=8000

# Configuraciones de Desarrollo
DEBUG=True
LOG_LEVEL=INFO
EOF
```

**Crear src/utils/config.py:**
```python
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
    MLFLOW_EXPERIMENT_NAME = os.getenv("MLFLOW_EXPERIMENT_NAME", "default")
    DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///mlflow.db")
    API_HOST = os.getenv("API_HOST", "0.0.0.0")
    API_PORT = int(os.getenv("API_PORT", 8000))
    DEBUG = os.getenv("DEBUG", "False").lower() == "true"
    LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")

config = Config()
```

#### Paso 3: Configuraci√≥n del Servidor MLFlow (10 minutos)
```bash
# Iniciar MLFlow UI en segundo plano
mlflow ui --host 0.0.0.0 --port 5000 &

# Verificar que est√° ejecut√°ndose
curl http://localhost:5000

# Abrir en navegador
echo "MLFlow UI: http://localhost:5000"
```

**Mostrar a los estudiantes la UI de MLFlow:**
- Navegar a http://localhost:5000
- Explicar la interfaz: Experiments, Runs, Models
- Mostrar estado vac√≠o antes de crear experimentos

### Lab 3: Primer Experimento MLFlow (75 minutos)

#### Paso 1: Crear Dataset de Muestra (15 minutos)
**Crear src/data/load_data.py:**
```python
import pandas as pd
import numpy as np
from sklearn.datasets import load_iris, load_wine, load_breast_cancer
from sklearn.model_selection import train_test_split
from typing import Tuple
import os

def load_iris_data() -> Tuple[pd.DataFrame, pd.Series]:
    """Cargar y retornar dataset iris como objetos pandas."""
    iris = load_iris()
    X = pd.DataFrame(iris.data, columns=iris.feature_names)
    y = pd.Series(iris.target, name='target')
    return X, y

def load_wine_data() -> Tuple[pd.DataFrame, pd.Series]:
    """Cargar y retornar dataset wine como objetos pandas."""
    wine = load_wine()
    X = pd.DataFrame(wine.data, columns=wine.feature_names)
    y = pd.Series(wine.target, name='target')
    return X, y

def get_train_test_split(X: pd.DataFrame, y: pd.Series, test_size: float = 0.2, random_state: int = 42):
    """Dividir datos en conjuntos de entrenamiento y prueba."""
    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)

def save_data(X_train, X_test, y_train, y_test, data_dir: str = "data"):
    """Guardar divisiones de entrenamiento/prueba en archivos CSV."""
    os.makedirs(data_dir, exist_ok=True)
    
    # Guardar datos de entrenamiento
    train_data = X_train.copy()
    train_data['target'] = y_train
    train_data.to_csv(f"{data_dir}/train.csv", index=False)
    
    # Guardar datos de prueba
    test_data = X_test.copy()
    test_data['target'] = y_test
    test_data.to_csv(f"{data_dir}/test.csv", index=False)
    
    print(f"Datos guardados en {data_dir}/")
    print(f"Forma train: {train_data.shape}")
    print(f"Forma test: {test_data.shape}")

if __name__ == "__main__":
    # Cargar datos
    X, y = load_iris_data()
    
    # Dividir datos
    X_train, X_test, y_train, y_test = get_train_test_split(X, y)
    
    # Guardar datos
    save_data(X_train, X_test, y_train, y_test)
```

**Ejecutar preparaci√≥n de datos:**
```bash
python src/data/load_data.py
ls data/
head data/train.csv
```

#### Paso 2: Crear Pipeline ML B√°sico (25 minutos)
**Crear src/models/train.py:**
```python
import mlflow
import mlflow.sklearn
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from src.utils.config import config
import argparse
import os

def load_data():
    """Cargar datos de entrenamiento y prueba."""
    train_data = pd.read_csv("data/train.csv")
    test_data = pd.read_csv("data/test.csv")
    
    X_train = train_data.drop('target', axis=1)
    y_train = train_data['target']
    X_test = test_data.drop('target', axis=1)
    y_test = test_data['target']
    
    return X_train, X_test, y_train, y_test

def train_model(model_type: str = "random_forest", **model_params):
    """Entrenar un modelo con seguimiento MLFlow."""
    
    # Configurar URI de seguimiento MLFlow y experimento
    mlflow.set_tracking_uri(config.MLFLOW_TRACKING_URI)
    mlflow.set_experiment(config.MLFLOW_EXPERIMENT_NAME)
    
    with mlflow.start_run() as run:
        # Registrar informaci√≥n de la ejecuci√≥n
        mlflow.set_tag("model_type", model_type)
        mlflow.set_tag("developer", "estudiante")
        mlflow.set_tag("purpose", "entrenamiento")
        
        # Cargar datos
        X_train, X_test, y_train, y_test = load_data()
        
        # Registrar informaci√≥n de datos
        mlflow.log_param("train_samples", len(X_train))
        mlflow.log_param("test_samples", len(X_test))
        mlflow.log_param("features", X_train.shape[1])
        mlflow.log_param("classes", len(np.unique(y_train)))
        
        # Crear modelo
        if model_type == "random_forest":
            model = RandomForestClassifier(**model_params)
        elif model_type == "logistic_regression":
            model = LogisticRegression(**model_params)
        else:
            raise ValueError(f"Tipo de modelo desconocido: {model_type}")
        
        # Registrar par√°metros del modelo
        for param, value in model_params.items():
            mlflow.log_param(param, value)
        
        # Entrenar modelo
        model.fit(X_train, y_train)
        
        # Hacer predicciones
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # Calcular m√©tricas
        train_accuracy = accuracy_score(y_train, y_pred_train)
        test_accuracy = accuracy_score(y_test, y_pred_test)
        test_precision = precision_score(y_test, y_pred_test, average='weighted')
        test_recall = recall_score(y_test, y_pred_test, average='weighted')
        test_f1 = f1_score(y_test, y_pred_test, average='weighted')
        
        # Registrar m√©tricas
        mlflow.log_metric("train_accuracy", train_accuracy)
        mlflow.log_metric("test_accuracy", test_accuracy)
        mlflow.log_metric("test_precision", test_precision)
        mlflow.log_metric("test_recall", test_recall)
        mlflow.log_metric("test_f1", test_f1)
        
        # Crear y guardar gr√°ficos
        create_confusion_matrix_plot(y_test, y_pred_test)
        create_feature_importance_plot(model, X_train.columns)
        
        # Registrar modelo
        mlflow.sklearn.log_model(
            model, 
            "model",
            registered_model_name=f"iris-{model_type}"
        )
        
        # Imprimir resultados
        print(f"Run ID: {run.info.run_id}")
        print(f"Modelo: {model_type}")
        print(f"Precisi√≥n Test: {test_accuracy:.4f}")
        print(f"MLFlow UI: {config.MLFLOW_TRACKING_URI}")
        
        return model, run.info.run_id

def create_confusion_matrix_plot(y_true, y_pred):
    """Crear y guardar gr√°fico de matriz de confusi√≥n."""
    plt.figure(figsize=(8, 6))
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matriz de Confusi√≥n')
    plt.ylabel('Etiqueta Verdadera')
    plt.xlabel('Etiqueta Predicha')
    plt.tight_layout()
    plt.savefig("confusion_matrix.png")
    mlflow.log_artifact("confusion_matrix.png", "plots")
    plt.close()

def create_feature_importance_plot(model, feature_names):
    """Crear y guardar gr√°fico de importancia de caracter√≠sticas."""
    if hasattr(model, 'feature_importances_'):
        plt.figure(figsize=(10, 6))
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=True)
        
        plt.barh(importance_df['feature'], importance_df['importance'])
        plt.title('Importancia de Caracter√≠sticas')
        plt.xlabel('Importancia')
        plt.tight_layout()
        plt.savefig("feature_importance.png")
        mlflow.log_artifact("feature_importance.png", "plots")
        plt.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model-type", default="random_forest", choices=["random_forest", "logistic_regression"])
    parser.add_argument("--n-estimators", type=int, default=100)
    parser.add_argument("--max-depth", type=int, default=None)
    parser.add_argument("--random-state", type=int, default=42)
    
    args = parser.parse_args()
    
    model_params = {
        "random_state": args.random_state
    }
    
    if args.model_type == "random_forest":
        model_params.update({
            "n_estimators": args.n_estimators,
            "max_depth": args.max_depth
        })
    
    model, run_id = train_model(args.model_type, **model_params)
    print(f"¬°Entrenamiento completado! Verificar MLFlow UI: {config.MLFLOW_TRACKING_URI}")
```

#### Paso 3: Ejecutar Primeros Experimentos (20 minutos)
```bash
# Ejecutar primer experimento con par√°metros por defecto
python src/models/train.py

# Ejecutar experimento con diferentes par√°metros
python src/models/train.py --model-type random_forest --n-estimators 50 --max-depth 5

# Ejecutar regresi√≥n log√≠stica
python src/models/train.py --model-type logistic_regression

# Ejecutar m√∫ltiples experimentos con diferentes par√°metros
python src/models/train.py --n-estimators 200 --max-depth 10
python src/models/train.py --n-estimators 50 --max-depth 3
```

#### Paso 4: Explorar MLFlow UI (15 minutos)
**Guiar a los estudiantes a trav√©s de MLFlow UI:**

1. **Navegar a http://localhost:5000**
2. **Explorar Experimentos:**
   - Hacer clic en el nombre del experimento
   - Comparar diferentes ejecuciones
   - Ordenar por m√©tricas

3. **Examinar Ejecuciones Individuales:**
   - Hacer clic en un run ID
   - Revisar par√°metros, m√©tricas, artefactos
   - Descargar artefactos

4. **Comparar Ejecuciones:**
   - Seleccionar m√∫ltiples ejecuciones
   - Hacer clic en bot√≥n "Compare"
   - Analizar relaciones par√°metro vs m√©trica

5. **Model Registry:**
   - Navegar a pesta√±a "Models"
   - Ver modelos registrados
   - Explorar versiones de modelos

**Preguntas de Discusi√≥n:**
- ¬øCu√°l modelo tuvo mejor rendimiento y por qu√©?
- ¬øC√≥mo afectan diferentes par√°metros al rendimiento?
- ¬øQu√© informaci√≥n es m√°s √∫til para debugging?

---

## üéØ Cierre de Sesi√≥n (10 minutos)

### Revisi√≥n de Logros Clave (5 minutos)
**Lo que logramos:**
1. ‚úÖ Entendimos fundamentos MLOps y valor empresarial
2. ‚úÖ Configuramos entorno de desarrollo profesional con uv
3. ‚úÖ Creamos primeros experimentos MLFlow con seguimiento apropiado
4. ‚úÖ Exploramos MLFlow UI para comparaci√≥n de experimentos
5. ‚úÖ Establecimos estructura de proyecto y mejores pr√°cticas

### Vista Previa de la Siguiente Sesi√≥n (3 minutos)
**Vista Previa Sesi√≥n 2:**
- MLFlow Model Registry Avanzado
- Selecci√≥n estrat√©gica de herramientas (marco de decisi√≥n MLFlow vs DVC)
- Estrategias integrales de testing ML
- Flujos de promoci√≥n de modelos

### Q&A y Soluci√≥n de Problemas (2 minutos)
**Problemas Comunes:**
- MLFlow UI no carga ‚Üí Verificar puerto 5000, reiniciar servidor
- Problemas instalaci√≥n uv ‚Üí M√©todos de instalaci√≥n alternativos
- Errores de importaci√≥n ‚Üí Verificar activaci√≥n de entorno virtual

---

## üìã Checkpoint de Evaluaci√≥n

### Preguntas de Verificaci√≥n de Conocimiento:
1. ¬øCu√°les son los cuatro componentes principales de MLFlow?
2. ¬øCu√°ndo elegir√≠a artefactos MLFlow sobre DVC para versionado de datos?
3. ¬øCu√°l es la diferencia entre par√°metros y m√©tricas en MLFlow?
4. ¬øC√≥mo asegurar reproducibilidad en experimentos ML?

### Verificaci√≥n Pr√°ctica:
- [ ] Estudiante tiene entorno uv funcionando
- [ ] MLFlow UI accesible y mostrando experimentos
- [ ] Al menos 3 ejecuciones de experimentos registradas
- [ ] Estructura de proyecto sigue mejores pr√°cticas
- [ ] Repositorio Git creado y comprometido

---

## üìé Recursos Adicionales

### Para Estudiantes:
- [Documentaci√≥n MLFlow](https://mlflow.org/docs/latest/)
- [Documentaci√≥n uv](https://docs.astral.sh/uv/)
- [Mejores Pr√°cticas Git para ML](https://dvc.org/doc/user-guide/how-to/data-management/git-best-practices)

### Para Instructores:
- Soluciones de problemas comunes
- Ejercicios extendidos para estudiantes avanzados
- Datasets alternativos para variedad

---

## üîß Gu√≠a de Soluci√≥n de Problemas

### Problemas Comunes de Estudiantes:

#### 1. Instalaci√≥n de uv Falla
**S√≠ntomas:** Command not found, errores SSL
**Soluciones:**
- Usar m√©todo de instalaci√≥n alternativo
- Verificar configuraciones de firewall corporativo
- Descargar binario manualmente desde releases de GitHub

#### 2. MLFlow UI No Inicia
**S√≠ntomas:** Puerto 5000 ya en uso, conexi√≥n rechazada
**Soluciones:**
```bash
# Verificar qu√© est√° usando puerto 5000
lsof -i :5000  # macOS/Linux
netstat -ano | findstr 5000  # Windows

# Usar puerto diferente
mlflow ui --port 5001

# Matar proceso existente
kill -9 [PID]
```

#### 3. Errores de Importaci√≥n
**S√≠ntomas:** ModuleNotFoundError
**Soluciones:**
```bash
# Verificar que entorno virtual est√° activado
which python
echo $VIRTUAL_ENV

# Reinstalar dependencias
uv sync --reinstall

# Verificar ruta Python
python -c "import sys; print(sys.path)"
```

#### 4. Problemas del Repositorio Git
**S√≠ntomas:** Permission denied, authentication failed
**Soluciones:**
- Configurar SSH keys para GitHub
- Usar personal access tokens
- Configurar credenciales Git apropiadamente

Este plan de sesi√≥n detallado proporciona todo lo necesario para ense√±ar exitosamente la Sesi√≥n 1, con timing claro, ejercicios pr√°cticos y gu√≠a de soluci√≥n de problemas.